{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZkMIazjsK8uY","executionInfo":{"status":"ok","timestamp":1764410961395,"user_tz":-540,"elapsed":14965,"user":{"displayName":"권준호","userId":"06664711965802495932"}},"outputId":"b91f7a62-f1ca-4e2d-eec8-906c857c5758"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import json\n","from collections import defaultdict\n","from typing import List, Dict, Set, Optional, Tuple\n","\n","def load_table_index(table_index_path):\n","    \"\"\"\n","    table_index.jsonl 파일을 로드하여 DB별 테이블 정보 생성\n","\n","    Args:\n","        table_index_path: table_index.jsonl 파일 경로\n","\n","    Returns:\n","        db_tables: {db_id: set(table_names_lower)} 형태의 딕셔너리\n","        table_info: 전체 테이블 정보 리스트\n","    \"\"\"\n","    db_tables = defaultdict(set)\n","    table_info = []\n","\n","    with open(table_index_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            data = json.loads(line.strip())\n","            db_id = data['db_id']\n","\n","            # table_name_db를 소문자로 저장 (실제 DB 테이블 이름)\n","            table_name = data['table_name_db'].lower()\n","            db_tables[db_id].add(table_name)\n","\n","            table_info.append(data)\n","\n","    return db_tables, table_info\n","\n","\n","def infer_db_id_from_tables(table_names: List[str], db_tables: Dict[str, Set[str]]) -> Optional[str]:\n","    \"\"\"\n","    MMQA 샘플의 table_names를 보고 Spider db_id를 추정하는 함수.\n","\n","    매칭 전략:\n","    1단계: table_names가 모두 포함되는 db_id 후보를 찾는다.\n","           - 후보가 1개면 그것을 사용\n","           - 후보가 여러 개면, 테이블 개수가 작은 DB를 선택 (더 작은 스키마 우선)\n","\n","    2단계(백업): 1단계에서 후보가 없으면,\n","           table_names와 가장 많이 겹치는(overlap) DB를 선택\n","           overlap가 0이면 None 반환\n","\n","    Args:\n","        table_names: 찾을 테이블 이름 리스트\n","        db_tables: {db_id: set(table_names)} 형태의 딕셔너리\n","\n","    Returns:\n","        해당하는 db_id 또는 None\n","    \"\"\"\n","    if not table_names:\n","        return None\n","\n","    # 입력 테이블 이름들을 소문자로 변환\n","    target_tables = {t.lower() for t in table_names}\n","\n","    # 1단계: 완전 포함하는 DB 찾기 (target ⊆ db_tables)\n","    full_match_candidates = []\n","    for db_id, tables in db_tables.items():\n","        if target_tables.issubset(tables):\n","            # (db_id, 해당 DB의 테이블 수)\n","            full_match_candidates.append((db_id, len(tables)))\n","\n","    if full_match_candidates:\n","        # 테이블 수가 적은 DB를 우선 선택 (더 작은 스키마)\n","        full_match_candidates.sort(key=lambda x: x[1])\n","        return full_match_candidates[0][0]\n","\n","    # 2단계: overlap가 가장 큰 DB 선택\n","    best_db = None\n","    best_overlap = 0\n","\n","    for db_id, tables in db_tables.items():\n","        overlap = len(target_tables & tables)\n","        if overlap > best_overlap:\n","            best_overlap = overlap\n","            best_db = db_id\n","\n","    # overlap가 0이면 None 반환\n","    if best_db is None or best_overlap == 0:\n","        return None\n","\n","    return best_db\n","\n","\n","def load_mmqa_data(path: str) -> List[Dict]:\n","    \"\"\"\n","    MMQA JSON 파일 로더\n","    - 전체가 하나의 JSON 리스트일 수도 있고\n","    - jsonl 형식(줄마다 JSON object)일 수도 있으니 둘 다 처리\n","    \"\"\"\n","    with open(path, 'r', encoding='utf-8') as f:\n","        text = f.read().strip()\n","\n","    # 먼저 전체를 JSON으로 파싱 시도\n","    try:\n","        data = json.loads(text)\n","        if isinstance(data, dict):\n","            # dict 한 개로 감싸져 있으면 values() 사용\n","            data = list(data.values())\n","        if not isinstance(data, list):\n","            raise ValueError(\"JSON is not a list\")\n","        return data\n","    except Exception:\n","        # 안 되면 jsonl 형식이라고 가정\n","        data = []\n","        for line in text.splitlines():\n","            line = line.strip()\n","            if not line:\n","                continue\n","            data.append(json.loads(line))\n","        return data\n","\n","\n","def preprocess_mmqa_data(input_json_path: str, table_index_path: str, output_json_path: str):\n","    \"\"\"\n","    MMQA JSON 파일을 전처리하여 새로운 형식으로 저장합니다.\n","\n","    Args:\n","        input_json_path: 입력 MMQA JSON 파일 경로\n","        table_index_path: table_index.jsonl 파일 경로\n","        output_json_path: 출력 JSON 파일 경로\n","    \"\"\"\n","    print(\"=\" * 70)\n","    print(\"MMQA 데이터 전처리 시작\")\n","    print(\"=\" * 70)\n","\n","    # table_index.jsonl 로딩\n","    print(\"\\n[1/4] table_index.jsonl 로딩 중...\")\n","    db_tables, table_info = load_table_index(table_index_path)\n","    print(f\"  ✓ 총 {len(db_tables)}개의 데이터베이스\")\n","    print(f\"  ✓ 총 {len(table_info)}개의 테이블\")\n","\n","    # MMQA 데이터 로딩\n","    print(\"\\n[2/4] MMQA 데이터 로딩 중...\")\n","    data = load_mmqa_data(input_json_path)\n","    print(f\"  ✓ 총 {len(data)}개 항목 로드 완료\")\n","\n","    # 데이터 전처리\n","    print(\"\\n[3/4] DB ID 매칭 및 전처리 중...\")\n","    processed_data = []\n","    db_id_stats = defaultdict(int)\n","    unmatched_items = []\n","    match_type_stats = defaultdict(int)  # 매칭 타입 통계\n","\n","    for idx, item in enumerate(data):\n","        table_names = item.get('table_names', [])\n","\n","        # DB ID 추론\n","        db_id = infer_db_id_from_tables(table_names, db_tables)\n","\n","        if db_id:\n","            db_id_stats[db_id] += 1\n","\n","            # 매칭 타입 확인 (완전 매칭 vs 부분 매칭)\n","            target_tables = {t.lower() for t in table_names}\n","            if target_tables.issubset(db_tables[db_id]):\n","                match_type_stats['full_match'] += 1\n","            else:\n","                match_type_stats['partial_match'] += 1\n","        else:\n","            unmatched_items.append({\n","                'id': item.get('id_', idx),\n","                'table_names': table_names,\n","                'question': item.get('Question', '')[:100]  # 질문 일부만 저장\n","            })\n","\n","        # 전처리된 데이터 구조 생성\n","        processed_item = {\n","            'id': item.get('id_', idx),\n","            'db_id': db_id,\n","            'question': item.get('Question', ''),\n","            'sql': item.get('SQL', ''),\n","            'table_names': table_names\n","        }\n","\n","        processed_data.append(processed_item)\n","\n","        # 진행상황 출력\n","        if (idx + 1) % 100 == 0:\n","            print(f\"  진행: {idx + 1}/{len(data)} ({(idx+1)/len(data)*100:.1f}%)\")\n","\n","    # 결과 파일 저장\n","    print(f\"\\n[4/4] 결과 파일 저장 중...\")\n","    with open(output_json_path, 'w', encoding='utf-8') as f:\n","        json.dump(processed_data, f, ensure_ascii=False, indent=2)\n","    print(f\"  ✓ 저장 완료: {output_json_path}\")\n","\n","    # 통계 정보 출력\n","    print(\"\\n\" + \"=\" * 70)\n","    print(\"전처리 완료 - 통계 정보\")\n","    print(\"=\" * 70)\n","\n","    db_ids_found = sum(1 for item in processed_data if item['db_id'] is not None)\n","    print(f\"\\n✓ 총 처리 항목: {len(processed_data)}\")\n","    print(f\"✓ DB ID 매칭 성공: {db_ids_found}/{len(processed_data)} ({db_ids_found/len(processed_data)*100:.1f}%)\")\n","    print(f\"✓ DB ID 매칭 실패: {len(unmatched_items)} ({len(unmatched_items)/len(processed_data)*100:.1f}%)\")\n","\n","    # 매칭 타입 통계\n","    if match_type_stats:\n","        print(f\"\\n[매칭 타입 분석]\")\n","        print(f\"  - 완전 매칭 (모든 테이블 포함): {match_type_stats.get('full_match', 0)}\")\n","        print(f\"  - 부분 매칭 (일부 테이블만): {match_type_stats.get('partial_match', 0)}\")\n","\n","    # DB별 분포\n","    if db_id_stats:\n","        print(f\"\\n[DB별 분포 - 상위 15개]\")\n","        sorted_dbs = sorted(db_id_stats.items(), key=lambda x: x[1], reverse=True)[:15]\n","        for rank, (db_id, count) in enumerate(sorted_dbs, 1):\n","            percentage = count / len(processed_data) * 100\n","            print(f\"  {rank:2d}. {db_id:25s}: {count:4d}개 ({percentage:5.1f}%)\")\n","\n","    # 매칭 실패 항목 상세\n","    if unmatched_items:\n","        print(f\"\\n[매칭 실패 항목 분석 - 최대 10개]\")\n","        for i, item in enumerate(unmatched_items[:10], 1):\n","            print(f\"\\n  [{i}] ID: {item['id']}\")\n","            print(f\"      테이블: {item['table_names']}\")\n","            print(f\"      질문: {item['question']}...\")\n","\n","            # 가능한 후보 DB 찾기 (부분 매칭)\n","            target = {t.lower() for t in item['table_names']}\n","            candidates = []\n","            for db_id, tables in db_tables.items():\n","                overlap = len(target & tables)\n","                if overlap > 0:\n","                    candidates.append((db_id, overlap, len(target)))\n","\n","            if candidates:\n","                candidates.sort(key=lambda x: x[1], reverse=True)\n","                best = candidates[0]\n","                print(f\"      가장 유사한 DB: {best[0]} (매칭: {best[1]}/{best[2]} 테이블)\")\n","\n","    print(\"\\n\" + \"=\" * 70)\n","\n","    return processed_data\n","\n","\n","# Google Colab 실행 예제\n","if __name__ == \"__main__\":\n","    # 파일 경로 설정\n","    input_json_path = '/content/drive/MyDrive/ai_intensive2/Synthesized_two_table.json'  # 입력 MMQA 파일\n","    table_index_path = '/content/drive/MyDrive/ai_intensive2/spider_data/preprocessed/table_index.jsonl'  # table_index.jsonl 파일\n","    output_json_path = '/content/drive/MyDrive/ai_intensive2/mmqa2.json'  # 출력 파일\n","\n","    # 전처리 실행\n","    processed_data = preprocess_mmqa_data(\n","        input_json_path,\n","        table_index_path,\n","        output_json_path\n","    )\n","\n","    # 샘플 데이터 출력\n","    print(\"\\n처리된 데이터 샘플 (처음 3개):\")\n","    print(\"=\" * 70)\n","    for i in range(min(3, len(processed_data))):\n","        print(f\"\\n[샘플 {i+1}]\")\n","        sample = processed_data[i]\n","        print(f\"ID: {sample['id']}\")\n","        print(f\"DB: {sample['db_id']}\")\n","        print(f\"Question: {sample['question'][:80]}...\")\n","        print(f\"Tables: {sample['table_names']}\")\n","        print(f\"SQL: {sample['sql'][:80]}...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCt8izGxN2p0","executionInfo":{"status":"ok","timestamp":1764312532684,"user_tz":-540,"elapsed":30125,"user":{"displayName":"박영진","userId":"18109757495848470463"}},"outputId":"1efd4c7e-cb47-43fe-bbca-10b523771bc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","MMQA 데이터 전처리 시작\n","======================================================================\n","\n","[1/4] table_index.jsonl 로딩 중...\n","  ✓ 총 166개의 데이터베이스\n","  ✓ 총 876개의 테이블\n","\n","[2/4] MMQA 데이터 로딩 중...\n","  ✓ 총 2592개 항목 로드 완료\n","\n","[3/4] DB ID 매칭 및 전처리 중...\n","  진행: 100/2592 (3.9%)\n","  진행: 200/2592 (7.7%)\n","  진행: 300/2592 (11.6%)\n","  진행: 400/2592 (15.4%)\n","  진행: 500/2592 (19.3%)\n","  진행: 600/2592 (23.1%)\n","  진행: 700/2592 (27.0%)\n","  진행: 800/2592 (30.9%)\n","  진행: 900/2592 (34.7%)\n","  진행: 1000/2592 (38.6%)\n","  진행: 1100/2592 (42.4%)\n","  진행: 1200/2592 (46.3%)\n","  진행: 1300/2592 (50.2%)\n","  진행: 1400/2592 (54.0%)\n","  진행: 1500/2592 (57.9%)\n","  진행: 1600/2592 (61.7%)\n","  진행: 1700/2592 (65.6%)\n","  진행: 1800/2592 (69.4%)\n","  진행: 1900/2592 (73.3%)\n","  진행: 2000/2592 (77.2%)\n","  진행: 2100/2592 (81.0%)\n","  진행: 2200/2592 (84.9%)\n","  진행: 2300/2592 (88.7%)\n","  진행: 2400/2592 (92.6%)\n","  진행: 2500/2592 (96.5%)\n","\n","[4/4] 결과 파일 저장 중...\n","  ✓ 저장 완료: /content/drive/MyDrive/ai_intensive2/mmqa2.json\n","\n","======================================================================\n","전처리 완료 - 통계 정보\n","======================================================================\n","\n","✓ 총 처리 항목: 2592\n","✓ DB ID 매칭 성공: 2592/2592 (100.0%)\n","✓ DB ID 매칭 실패: 0 (0.0%)\n","\n","[매칭 타입 분석]\n","  - 완전 매칭 (모든 테이블 포함): 2592\n","  - 부분 매칭 (일부 테이블만): 0\n","\n","[DB별 분포 - 상위 15개]\n","   1. tracking_orders          :   65개 (  2.5%)\n","   2. college_1                :   54개 (  2.1%)\n","   3. music_1                  :   52개 (  2.0%)\n","   4. customers_card_transactions:   50개 (  1.9%)\n","   5. chinook_1                :   50개 (  1.9%)\n","   6. baseball_1               :   48개 (  1.9%)\n","   7. movie_1                  :   46개 (  1.8%)\n","   8. world_1                  :   45개 (  1.7%)\n","   9. e_learning               :   44개 (  1.7%)\n","  10. dog_kennels              :   44개 (  1.7%)\n","  11. driving_school           :   43개 (  1.7%)\n","  12. car_1                    :   40개 (  1.5%)\n","  13. college_2                :   40개 (  1.5%)\n","  14. activity_1               :   40개 (  1.5%)\n","  15. hospital_1               :   38개 (  1.5%)\n","\n","======================================================================\n","\n","처리된 데이터 샘플 (처음 3개):\n","======================================================================\n","\n","[샘플 1]\n","ID: 0\n","DB: department_management\n","Question: Which department currently headed by a temporary acting manager has the largest ...\n","Tables: ['department', 'management']\n","SQL: SELECT d.Name, SUM(d.Num_Employees) FROM department d JOIN management m ON d.Dep...\n","\n","[샘플 2]\n","ID: 1\n","DB: department_management\n","Question: What are the names and budgets of departments ranked in the top 10 whose current...\n","Tables: ['department', 'management']\n","SQL: SELECT d.Name, d.Budget_in_Billions FROM department d JOIN management m ON d.Dep...\n","\n","[샘플 3]\n","ID: 2\n","DB: department_management\n","Question: What is the average age of department heads who are serving as temporary acting ...\n","Tables: ['head', 'management']\n","SQL: SELECT AVG(h.age) FROM head h JOIN management m ON h.head_ID = m.head_ID WHERE m...\n"]}]},{"cell_type":"markdown","source":["---\n","### train, test 분리"],"metadata":{"id":"ao3VRy9DFi50"}},{"cell_type":"code","source":["\n","import json\n","import os\n","import random\n","\n","BASE_DIR = \"/content/drive/MyDrive/ai_intensive2\"\n","\n","def split_mmqa_json(\n","    filename: str,\n","    train_ratio: float = 0.2,\n","    seed: int = 42,\n","):\n","    \"\"\"\n","    MMQA json 파일을 읽어서\n","      - db_id null/빈 값 개수 출력\n","      - train_ratio 비율만큼 train, 나머지 test로 분리\n","      - *_train.json, *_test.json 으로 저장\n","    \"\"\"\n","    path = os.path.join(BASE_DIR, filename)\n","    print(\"=\" * 70)\n","    print(f\"[INFO] Processing file: {path}\")\n","\n","    # 1) JSON 로드\n","    with open(path, \"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f)\n","\n","    total = len(data)\n","    print(f\"[INFO] Total samples: {total}\")\n","\n","    # 2) db_id가 None / 빈 문자열 / 키 없음인 샘플 체크\n","    missing_dbid = [\n","        ex for ex in data\n","        if (\"db_id\" not in ex) or (ex[\"db_id\"] is None) or (ex[\"db_id\"] == \"\")\n","    ]\n","    print(f\"[CHECK] #samples with missing/empty db_id: {len(missing_dbid)}\")\n","\n","    # 일부 예시 출력 (id가 있으면 id만, 없으면 앞부분)\n","    if missing_dbid:\n","        print(\"[CHECK] Examples with missing db_id (up to 5):\")\n","        for ex in missing_dbid[:5]:\n","            print(\"  - id:\", ex.get(\"id\"), \"| db_id:\", ex.get(\"db_id\"))\n","\n","    # 3) 랜덤 셔플 + 20% / 80% split\n","    rng = random.Random(seed)\n","    rng.shuffle(data)\n","\n","    n_train = int(len(data) * train_ratio)\n","    train_data = data[:n_train]\n","    test_data  = data[n_train:]\n","\n","    print(f\"[SPLIT] train: {len(train_data)}  ({train_ratio*100:.1f}%)\")\n","    print(f\"[SPLIT] test : {len(test_data)}  ({(1-train_ratio)*100:.1f}%)\")\n","\n","    # 4) 저장 경로 생성\n","    name, ext = os.path.splitext(filename)  # ex) mmqa2, .json\n","    train_path = os.path.join(BASE_DIR, f\"{name}_train.json\")\n","    test_path  = os.path.join(BASE_DIR, f\"{name}_test.json\")\n","\n","    with open(train_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(train_data, f, ensure_ascii=False, indent=2)\n","\n","    with open(test_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(test_data, f, ensure_ascii=False, indent=2)\n","\n","    print(f\"[SAVE] Train saved to: {train_path}\")\n","    print(f\"[SAVE] Test  saved to: {test_path}\")\n","    print()\n","\n","\n","# 실제 실행: mmqa2, mmqa3 각각 20% train / 80% test\n","split_mmqa_json(\"mmqa2.json\", train_ratio=0.2, seed=42)\n","split_mmqa_json(\"mmqa3.json\", train_ratio=0.2, seed=42)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_oTAyKdFiM-","executionInfo":{"status":"ok","timestamp":1764410965207,"user_tz":-540,"elapsed":1565,"user":{"displayName":"권준호","userId":"06664711965802495932"}},"outputId":"6de8d943-0a73-4049-806c-3cf35cf960c6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","[INFO] Processing file: /content/drive/MyDrive/ai_intensive2/mmqa2.json\n","[INFO] Total samples: 2592\n","[CHECK] #samples with missing/empty db_id: 0\n","[SPLIT] train: 518  (20.0%)\n","[SPLIT] test : 2074  (80.0%)\n","[SAVE] Train saved to: /content/drive/MyDrive/ai_intensive2/mmqa2_train.json\n","[SAVE] Test  saved to: /content/drive/MyDrive/ai_intensive2/mmqa2_test.json\n","\n","======================================================================\n","[INFO] Processing file: /content/drive/MyDrive/ai_intensive2/mmqa3.json\n","[INFO] Total samples: 721\n","[CHECK] #samples with missing/empty db_id: 0\n","[SPLIT] train: 144  (20.0%)\n","[SPLIT] test : 577  (80.0%)\n","[SAVE] Train saved to: /content/drive/MyDrive/ai_intensive2/mmqa3_train.json\n","[SAVE] Test  saved to: /content/drive/MyDrive/ai_intensive2/mmqa3_test.json\n","\n"]}]}]}